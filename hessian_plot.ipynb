{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(columns=['class','grids','density', 'name', 'l_max', 'l_min', 'l_ratio', 'val_acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'cifar10' # cifar10 or cifar100\n",
    "loss_types = ['CE']\n",
    "train_rules = ['DRW']\n",
    "sams = [False, True]\n",
    "if dataset=='cifar10':\n",
    "    classes = [0,1,2,3,4,5,6,7,8,9,-1]\n",
    "elif dataset=='cifar100':\n",
    "    classes = [0,49,99,-1] \n",
    "dataloader_hesss = ['val']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian(x, x0, sigma_squared):\n",
    "    return np.exp(-(x0 - x)**2 /\n",
    "                  (2.0 * sigma_squared)) / np.sqrt(2 * np.pi * sigma_squared)\n",
    "\n",
    "def density_generate(eigenvalues,\n",
    "                     weights,\n",
    "                     num_bins=10000,\n",
    "                     sigma_squared=1e-5,\n",
    "                     overhead=0.01):\n",
    "\n",
    "    eigenvalues = np.array(eigenvalues)\n",
    "    weights = np.array(weights)\n",
    "\n",
    "    lambda_max = np.mean(np.max(eigenvalues, axis=1), axis=0) + overhead\n",
    "    lambda_min = np.mean(np.min(eigenvalues, axis=1), axis=0) - overhead\n",
    "\n",
    "    grids = np.linspace(lambda_min, lambda_max, num=num_bins)\n",
    "    sigma = sigma_squared * max(1, (lambda_max - lambda_min))\n",
    "\n",
    "    num_runs = eigenvalues.shape[0]\n",
    "    density_output = np.zeros((num_runs, num_bins))\n",
    "\n",
    "    for i in range(num_runs):\n",
    "        for j in range(num_bins):\n",
    "            x = grids[j]\n",
    "            tmp_result = gaussian(eigenvalues[i, :], x, sigma)\n",
    "            density_output[i, j] = np.sum(tmp_result * weights[i, :])\n",
    "    density = np.mean(density_output, axis=0)\n",
    "    normalization = np.sum(density) * (grids[1] - grids[0])\n",
    "    density = density / normalization\n",
    "    return density, grids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (1, 100)\n",
      "0 94.9\n",
      "1 (1, 100)\n",
      "1 97.8\n",
      "2 (1, 100)\n",
      "2 81.3\n",
      "3 (1, 100)\n",
      "3 74.700005\n",
      "4 (1, 100)\n",
      "4 80.3\n",
      "5 (1, 100)\n",
      "5 68.9\n",
      "6 (1, 100)\n",
      "6 78.4\n",
      "7 (1, 100)\n",
      "7 65.600006\n",
      "8 (1, 100)\n",
      "8 56.9\n",
      "9 (1, 100)\n",
      "9 62.000004\n",
      "-1 (1, 100)\n",
      "-1 76.08\n",
      "0 (1, 100)\n",
      "0 87.4\n",
      "1 (1, 100)\n",
      "1 93.3\n",
      "2 (1, 100)\n",
      "2 70.4\n",
      "3 (1, 100)\n",
      "3 60.800003\n",
      "4 (1, 100)\n",
      "4 79.0\n",
      "5 (1, 100)\n",
      "5 68.5\n",
      "6 (1, 100)\n",
      "6 82.100006\n",
      "7 (1, 100)\n",
      "7 65.700005\n",
      "8 (1, 100)\n",
      "8 78.100006\n",
      "9 (1, 100)\n",
      "9 75.9\n",
      "-1 (1, 100)\n",
      "-1 76.119995\n"
     ]
    }
   ],
   "source": [
    "for loss_type, train_rule in zip(loss_types, train_rules):\n",
    "    for sam in sams:\n",
    "        for dataloader_hess in dataloader_hesss:\n",
    "            # eigenvalues_overall = np.empty((0,100))\n",
    "            # weights_overall = np.empty((0,100))\n",
    "            if sam == True:\n",
    "                path = f'checkpoint/hessian_{dataset}_resnet32_{loss_type}_{train_rule}_exp_0.01_sam_0.8_sched_none_seed_None_0_{dataloader_hess}_{loss_type}_None_sample/'\n",
    "            else:\n",
    "                path = f'checkpoint/hessian_{dataset}_resnet32_{loss_type}_{train_rule}_exp_0.01_seed_None_0_{dataloader_hess}_{loss_type}_None_sample/'\n",
    "            val_accs = pd.read_csv(path+'accuracies.csv')\n",
    "            for cls in classes:\n",
    "                eigenvalues  = np.load(path+f'{cls}_density_eigen.npy')\n",
    "                weights = np.load(path+f'{cls}_density_weights.npy')\n",
    "                print(cls,eigenvalues.shape)\n",
    "                # eigenvalues_overall = np.append(eigenvalues_overall, eigenvalues, axis=0) \n",
    "                # weights_overall = np.append(weights_overall, weights, axis=0)   \n",
    "                density, grids = density_generate(eigenvalues, weights)\n",
    "                density = density + 1e-7\n",
    "                lambda_min = np.min(eigenvalues)\n",
    "                lambda_max = np.max(eigenvalues)\n",
    "                lambda_ratio = lambda_max/lambda_min\n",
    "                val_acc = val_accs[val_accs['Class']==cls]['Accuracy'].values[0]\n",
    "                print(cls,val_acc)\n",
    "                # val_acc = val_accs[cls]\n",
    "                name = dataset+loss_type+train_rule+str(sam)+dataloader_hess\n",
    "                name = f'dataset:{dataset}<br>loss_type:{loss_type}<br>train_rule:{train_rule}<br>sam:{sam}<br>dataloader_hess:{dataloader_hess}<br>'\n",
    "                df_temp = pd.DataFrame({'class':cls,'grids':grids,'density':density, 'name':name, 'text':cls, 'l_max':lambda_max, 'l_min':lambda_min, 'l_ratio':lambda_ratio, 'val_acc':val_acc})\n",
    "                df = pd.concat([df,df_temp],ignore_index=True)\n",
    "            # density, grids = density_generate(eigenvalues_overall, weights_overall)\n",
    "            # density = density + 1e-7\n",
    "            # lambda_min = np.min(eigenvalues_overall)\n",
    "            # lambda_max = np.max(eigenvalues_overall)\n",
    "            # lambda_ratio = lambda_max/lambda_min\n",
    "            # name = f'dataset:{dataset}<br>loss_type:{loss_type}<br>train_rule:{train_rule}<br>sam:{sam}<br>dataloader_hess:{dataloader_hess}<br>'\n",
    "            # df_temp = pd.DataFrame({'class':'overall','grids':grids,'density':density, 'name':name, 'text':cls, 'l_max':lambda_max, 'l_min':lambda_min, 'l_ratio':lambda_ratio, val_acc:np.mean(np.array(val_accs))})\n",
    "            # df = pd.concat([df,df_temp],ignore_index=True)\n",
    "\n",
    "# sort by class and x values\n",
    "df = df.sort_values(by=['class','grids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.line(df, x=\"grids\", y=\"density\", color='name', facet_col='class', hover_data=['l_max','l_min','l_ratio', 'val_acc'], facet_row='name', log_y=True)\n",
    "# fig.update_xaxes(matches=None)\n",
    "# fig.update_yaxes(matches=None)\n",
    "fig.write_html(f'checkpoint/{dataset}.html')\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
