{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(columns=['class','grids','density', 'name', 'l_max', 'l_min', 'l_ratio', 'val_acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian(x, x0, sigma_squared):\n",
    "    return np.exp(-(x0 - x)**2 /\n",
    "                  (2.0 * sigma_squared)) / np.sqrt(2 * np.pi * sigma_squared)\n",
    "\n",
    "def density_generate(eigenvalues,\n",
    "                     weights,\n",
    "                     num_bins=10000,\n",
    "                     sigma_squared=1e-5,\n",
    "                     overhead=0.01):\n",
    "\n",
    "    eigenvalues = np.array(eigenvalues)\n",
    "    weights = np.array(weights)\n",
    "\n",
    "    lambda_max = np.mean(np.max(eigenvalues, axis=1), axis=0) + overhead\n",
    "    lambda_min = np.mean(np.min(eigenvalues, axis=1), axis=0) - overhead\n",
    "\n",
    "    grids = np.linspace(lambda_min, lambda_max, num=num_bins)\n",
    "    sigma = sigma_squared * max(1, (lambda_max - lambda_min))\n",
    "\n",
    "    num_runs = eigenvalues.shape[0]\n",
    "    density_output = np.zeros((num_runs, num_bins))\n",
    "\n",
    "    for i in range(num_runs):\n",
    "        for j in range(num_bins):\n",
    "            x = grids[j]\n",
    "            tmp_result = gaussian(eigenvalues[i, :], x, sigma)\n",
    "            density_output[i, j] = np.sum(tmp_result * weights[i, :])\n",
    "    density = np.mean(density_output, axis=0)\n",
    "    normalization = np.sum(density) * (grids[1] - grids[0])\n",
    "    density = density / normalization\n",
    "    return density, grids\n",
    "\n",
    "def read_log(name,dataset):\n",
    "    with open(f'log/{name}/log_test.csv', 'r') as file:\n",
    "        lines = file.readlines()\n",
    "    best = 0\n",
    "    best_line = 0\n",
    "    for i,j in enumerate(lines):\n",
    "        if 'Best Prec@1' in j:\n",
    "            current = j.split(' ')[-1]\n",
    "            if float(current)>best:\n",
    "                best = float(current)\n",
    "                best_line = i\n",
    "    if dataset=='cifar10':\n",
    "        return eval(lines[best_line-1].split(' ')[-1])\n",
    "    elif dataset=='cifar100':\n",
    "        final_line = ''\n",
    "        for i in range(best_line-9,best_line):\n",
    "            final_line += lines[i].rstrip('\\n').lstrip(' ')\n",
    "        return eval(final_line.split(' ')[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'cifar100' # cifar10 or cifar100\n",
    "loss_types = ['CE','CE','LDAM']\n",
    "train_rules = ['None','DRW','DRW']\n",
    "sams = [False, True]\n",
    "if dataset=='cifar10':\n",
    "    classes = [0,4,9]\n",
    "elif dataset=='cifar100':\n",
    "    classes = [0,49,99] \n",
    "dataloader_hesss = ['train','val']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (1, 100)\n",
      "49 (1, 100)\n",
      "99 (1, 100)\n",
      "0 (1, 100)\n",
      "49 (1, 100)\n",
      "99 (1, 100)\n",
      "0 (1, 100)\n",
      "49 (1, 100)\n",
      "99 (1, 100)\n",
      "0 (1, 100)\n",
      "49 (1, 100)\n",
      "99 (1, 100)\n",
      "0 (1, 100)\n",
      "49 (1, 100)\n",
      "99 (1, 100)\n",
      "0 (1, 100)\n",
      "49 (1, 100)\n",
      "99 (1, 100)\n",
      "0 (1, 100)\n",
      "49 (1, 100)\n",
      "99 (1, 100)\n",
      "0 (1, 100)\n",
      "49 (1, 100)\n",
      "99 (1, 100)\n",
      "0 (1, 100)\n",
      "49 (1, 100)\n",
      "99 (1, 100)\n",
      "0 (1, 100)\n",
      "49 (1, 100)\n",
      "99 (1, 100)\n",
      "0 (1, 100)\n",
      "49 (1, 100)\n",
      "99 (1, 100)\n",
      "0 (1, 100)\n",
      "49 (1, 100)\n",
      "99 (1, 100)\n"
     ]
    }
   ],
   "source": [
    "for loss_type, train_rule in zip(loss_types, train_rules):\n",
    "    for sam in sams:\n",
    "        for dataloader_hess in dataloader_hesss:\n",
    "            eigenvalues_overall = np.empty((0,100))\n",
    "            weights_overall = np.empty((0,100))\n",
    "            if sam==True:\n",
    "                val_accs = read_log(f'{dataset}_resnet32_{loss_type}_{train_rule}_exp_0.01_sam_0.8_sched_none_seed_None_0', dataset)\n",
    "            else:\n",
    "                val_accs = read_log(f'{dataset}_resnet32_{loss_type}_{train_rule}_exp_0.01_seed_None_0', dataset)\n",
    "            for cls in classes:\n",
    "                if sam==False:\n",
    "                    eigenvalues  = np.load(f'checkpoint/hessian_{dataset}_resnet32_{loss_type}_{train_rule}_exp_0.01_seed_None_0_{dataloader_hess}_{loss_type}_None_sample/{cls}_density_eigen.npy')\n",
    "                    weights = np.load(f'checkpoint/hessian_{dataset}_resnet32_{loss_type}_{train_rule}_exp_0.01_seed_None_0_{dataloader_hess}_{loss_type}_None_sample/{cls}_density_weights.npy')\n",
    "                else:\n",
    "                    eigenvalues = np.load(f'checkpoint/hessian_{dataset}_resnet32_{loss_type}_{train_rule}_exp_0.01_sam_0.8_sched_none_seed_None_0_{dataloader_hess}_{loss_type}_None_sample/{cls}_density_eigen.npy')\n",
    "                    weights = np.load(f'checkpoint/hessian_{dataset}_resnet32_{loss_type}_{train_rule}_exp_0.01_sam_0.8_sched_none_seed_None_0_{dataloader_hess}_{loss_type}_None_sample/{cls}_density_weights.npy')\n",
    "                print(cls,eigenvalues.shape)\n",
    "                eigenvalues_overall = np.append(eigenvalues_overall, eigenvalues, axis=0) \n",
    "                weights_overall = np.append(weights_overall, weights, axis=0)   \n",
    "                density, grids = density_generate(eigenvalues, weights)\n",
    "                density = density + 1e-7\n",
    "                lambda_min = np.min(eigenvalues)\n",
    "                lambda_max = np.max(eigenvalues)\n",
    "                lambda_ratio = lambda_max/lambda_min\n",
    "                val_acc = val_accs[cls]\n",
    "                name = dataset+loss_type+train_rule+str(sam)+dataloader_hess\n",
    "                name = f'dataset:{dataset}<br>loss_type:{loss_type}<br>train_rule:{train_rule}<br>sam:{sam}<br>dataloader_hess:{dataloader_hess}<br>'\n",
    "                df_temp = pd.DataFrame({'class':cls,'grids':grids,'density':density, 'name':name, 'text':cls, 'l_max':lambda_max, 'l_min':lambda_min, 'l_ratio':lambda_ratio, 'val_acc':val_acc})\n",
    "                df = pd.concat([df,df_temp],ignore_index=True)\n",
    "            density, grids = density_generate(eigenvalues_overall, weights_overall)\n",
    "            density = density + 1e-7\n",
    "            lambda_min = np.min(eigenvalues_overall)\n",
    "            lambda_max = np.max(eigenvalues_overall)\n",
    "            lambda_ratio = lambda_max/lambda_min\n",
    "            name = f'dataset:{dataset}<br>loss_type:{loss_type}<br>train_rule:{train_rule}<br>sam:{sam}<br>dataloader_hess:{dataloader_hess}<br>'\n",
    "            df_temp = pd.DataFrame({'class':'overall','grids':grids,'density':density, 'name':name, 'text':cls, 'l_max':lambda_max, 'l_min':lambda_min, 'l_ratio':lambda_ratio, val_acc:np.mean(np.array(val_accs))})\n",
    "            df = pd.concat([df,df_temp],ignore_index=True)\n",
    "\n",
    "# sort by class and x values\n",
    "df = df.sort_values(by=['class','grids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.line(df, x=\"grids\", y=\"density\", color='name', facet_col='class', hover_data=['l_max','l_min','l_ratio', 'val_acc'], facet_row='name', log_y=True)\n",
    "fig.update_xaxes(matches=None)\n",
    "fig.update_yaxes(matches=None)\n",
    "fig.write_html(f'checkpoint/{dataset}.html')\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
